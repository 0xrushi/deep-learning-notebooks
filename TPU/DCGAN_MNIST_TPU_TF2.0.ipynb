{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "dcgan_with_TPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF2x3qooyBTI"
      },
      "source": [
        "# Deep Convolutional Generative Adversarial Network using TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITZuApL56Mny"
      },
      "source": [
        "This tutorial demonstrates how to generate images of handwritten digits using a [Deep Convolutional Generative Adversarial Network](https://arxiv.org/pdf/1511.06434.pdf) (DCGAN). The code is written using the [Keras Sequential API](https://www.tensorflow.org/guide/keras) with a `tf.GradientTape` training loop and colab TPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZKbyU2-AiY-"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wx-zNbLqB4K8",
        "outputId": "c7f21394-f128-4221-8751-5cd5efc4a8c8"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfIk2es3hJEd"
      },
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display\n",
        "import datetime\n",
        "log_dir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1JJrMD0ej5R"
      },
      "source": [
        "### added for tpu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzvYrcdTeiJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa89b92b-53fa-4314-fb2d-c781f3e6c9aa"
      },
      "source": [
        "# Initialize TPU\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU@{}'.format(tpu.master()))\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "    \n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    \n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    \n",
        "REPLICAS = strategy.num_replicas_in_sync \n",
        "print('# REPLICAS: {}'.format(REPLICAS))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU@grpc://10.11.40.66:8470\n",
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.11.40.66:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.11.40.66:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# REPLICAS: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYn4MdZnKCey"
      },
      "source": [
        "### Load and prepare the dataset\n",
        "\n",
        "You will use the MNIST dataset to train the generator and the discriminator. The generator will generate handwritten digits resembling the MNIST data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4fYMGxGhrna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c12ca2-6fcf-4034-f457-cf88b2d5e118"
      },
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFC2ghIdiZYE"
      },
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4PIDhoDLbsZ"
      },
      "source": [
        "BUFFER_SIZE = 2048\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8op0yT8Q39y"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE                                    # For accessing data parallelly.\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE * strategy.num_replicas_in_sync              \n",
        "BS = 128      "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yKCCQOoJ7cn"
      },
      "source": [
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(2048).batch(BS,drop_remainder=True).prefetch(AUTOTUNE)  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYMDSj6t92Ts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5443e210-58dc-412b-f9f6-b4e3fe055961"
      },
      "source": [
        "x = train_dataset.unbatch().batch(20)\n",
        "train_batch = iter(x)\n",
        "next(train_batch)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20, 28, 28, 1), dtype=float32, numpy=\n",
              "array([[[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]],\n",
              "\n",
              "\n",
              "       [[[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]],\n",
              "\n",
              "        [[-1.],\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         ...,\n",
              "         [-1.],\n",
              "         [-1.],\n",
              "         [-1.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "lzsL2ZlvWd2e",
        "outputId": "b4a086ac-a043-4973-eb92-c710f2fd0485"
      },
      "source": [
        "plt.imshow(tf.reshape(next(train_batch)[0, :, :,:], [28,28]), cmap='gray')\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5bbde475d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THY-sZMiQ4UV"
      },
      "source": [
        "## Create the models\n",
        "\n",
        "Both the generator and discriminator are defined using the [Keras Sequential API](https://www.tensorflow.org/guide/keras#sequential_model)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tEyxE-GMC48"
      },
      "source": [
        "### The Generator\n",
        "\n",
        "The generator uses `tf.keras.layers.Conv2DTranspose` (upsampling) layers to produce an image from a seed (random noise). Start with a `Dense` layer that takes this seed as input, then upsample several times until you reach the desired image size of 28x28x1. Notice the `tf.keras.layers.LeakyReLU` activation for each layer, except the output layer which uses tanh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bpTcDqoLWjY"
      },
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyWgG09LCSJl"
      },
      "source": [
        "Use the (as yet untrained) generator to create an image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl7jcC7TdPTG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "89a2cc6c-fff3-4ad1-9599-86e5e7e8b573"
      },
      "source": [
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5bbd31e5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0IKnaCtg6WE"
      },
      "source": [
        "### The Discriminator\n",
        "\n",
        "The discriminator is a CNN-based image classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw2tPLmk2pEP"
      },
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhPneagzCaQv"
      },
      "source": [
        "Use the (as yet untrained) discriminator to classify the generated images as real or fake. The model will be trained to output positive values for real images, and negative values for fake images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDkA05NE6QMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ff1ba6-c82f-4a26-b6f5-c28129f108b7"
      },
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[-0.00099014]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzl4O2iruqAs"
      },
      "source": [
        "### Define losses in TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3QFe7ybCTbD"
      },
      "source": [
        "with strategy.scope():                                                                            # Note, I initialize the loss functions under the strategy's scope\n",
        "    loss_object = tf.keras.losses.BinaryCrossentropy(\n",
        "    from_logits=True, \n",
        "    reduction= tf.keras.losses.Reduction.NONE)                                                    # Set reduction to `none` so we can do the reduction afterwards and \n",
        "                                                                                                  # divide by global batch size/\n",
        "    \n",
        "    \n",
        "    def generator_loss(fake_output):\n",
        "        per_example_loss =  loss_object(tf.ones_like(fake_output), fake_output)                   # Getting the unscaled loss.\n",
        "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)  # 'tf.nn.compute_average_loss()' takes the unscaled loss and \n",
        "                                                                                                  # GLOBAL_BATCH_SIZE and scale it according to -> \n",
        "                                                                                                  # scale_loss = tf.reduce_sum(loss) * (1. / GLOBAL_BATCH_SIZE)\n",
        "    \n",
        "    def discriminator_loss(real_output, fake_output):                                             # Same goes for the discriminator_loss\n",
        "        real_loss = loss_object(tf.ones_like(real_output), real_output)\n",
        "        fake_loss = loss_object(tf.zeros_like(fake_output), fake_output)\n",
        "        total_loss  = real_loss + fake_loss\n",
        "        return tf.nn.compute_average_loss(total_loss, global_batch_size=GLOBAL_BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFducln8ulHx"
      },
      "source": [
        "### Instantiate the Generator and discriminator under the scope for TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5iLNFxoukqD"
      },
      "source": [
        "with strategy.scope():\n",
        "    generator = make_generator_model()                                              # Instantiate the Generator and discriminator under the scope!\n",
        "    discriminator = make_discriminator_model()\n",
        "    \n",
        "    generator_optimizer = tf.keras.optimizers.Adam(1e-4)                            # Create the optimizers, here using 2 differnt objects but with same LR\n",
        "    discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)     \n",
        "    \n",
        "    # checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,       # Create the checkpoint object to store intermediate states of the optimizers and models\n",
        "    #                              discriminator_optimizer=discriminator_optimizer,\n",
        "    #                              generator=generator,\n",
        "    #                              discriminator=discriminator)\n",
        "    # checkpoint_dir = './training_checkpoints'\n",
        "    # checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "    checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                    discriminator_optimizer=discriminator_optimizer,\n",
        "                                    generator=generator,\n",
        "                                    discriminator=discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw1fkAczTQYh"
      },
      "source": [
        "## Define the training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS2GWywBbAWo"
      },
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jylSonrqSWfi"
      },
      "source": [
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t5ibNo05jCB"
      },
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "gen_loss_results = []\n",
        "disc_loss_results = []\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "      gen_loss_results.append(gen_loss)\n",
        "      disc_loss_results.append(disc_loss)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9OxKjv0DPl6"
      },
      "source": [
        "@tf.function\n",
        "def distributed_train_step(dataset_inputs):\n",
        "    '''\n",
        "    Computes per replica losses of a single step and return the scaled losses!\n",
        "    '''\n",
        "    # `run` replicates the provided computation and runs it with the distributed input.\n",
        "    \n",
        "    per_replica_gloss, per_replica_dloss = strategy.run(train_step, args=(dataset_inputs,))\n",
        "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_gloss,axis=None), strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_dloss,axis=None)\n",
        "\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    start = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        gloss = 0.0\n",
        "        dloss = 0.0\n",
        "        num_batches = 0\n",
        "        for image_batch in (dataset):                                                  # Iterate the dataset.\n",
        "            G, D = distributed_train_step(image_batch)                                 # Get the scaled losses for the generator and discriminator.\n",
        "            gloss += G                                                                \n",
        "            dloss += D\n",
        "            num_batches +=1\n",
        "            total_loss = gloss+dloss\n",
        "        \n",
        "        display.clear_output(wait=True)\n",
        "\n",
        "        train_loss = total_loss/ num_batches\n",
        "        gloss = gloss/num_batches\n",
        "        dloss = dloss/num_batches\n",
        "        if epoch %15 ==0:\n",
        "            template = (\"Epoch {}\\n G-Loss {}\\n D-Loss {}\\n Train-loss {} \\n Time elapsed {}\")\n",
        "            print(template.format(epoch+1, gloss,dloss,train_loss, time.time()-start))\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aFF7Hk3XdeW"
      },
      "source": [
        "**Generate and save images**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZrd4CdjR-Fp"
      },
      "source": [
        "## Train the model\n",
        "Call the `train()` method defined above to train the generator and discriminator simultaneously. Note, training GANs can be tricky. It's important that the generator and discriminator do not overpower each other (e.g., that they train at a similar rate).\n",
        "\n",
        "At the beginning of the training, the generated images look like random noise. As training progresses, the generated digits will look increasingly real. After about 50 epochs, they resemble MNIST digits. This may take about one minute / epoch with the default settings on Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly3UN0SLLY2l",
        "outputId": "b99df30c-ba22-4b43-ace3-7f1101262e32"
      },
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46\n",
            " G-Loss 0.943254828453064\n",
            " D-Loss 1.2478402853012085\n",
            " Train-loss 2.1910951137542725 \n",
            " Time elapsed 298.02968192100525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfM4YcPVPkNO"
      },
      "source": [
        "Restore the latest checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhXsd0srPo8c"
      },
      "source": [
        "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "WAh42wOWJJSL",
        "outputId": "1025cdbd-a9a3-4be4-b7d3-4edd401fb34c"
      },
      "source": [
        "noise = tf.random.normal([1, noise_dim])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "# plt.imshow(tf.reshape(generated_image[0, :, :,:], [28,28]), cmap='hot')\n",
        "plt.imshow(generated_image[0, :, :,0], cmap='gray')\n",
        "\n",
        "\n",
        "decision = discriminator(generated_image)\n",
        "print(decision)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[-1.0455761]], shape=(1, 1), dtype=float32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NywiH3nL8guF"
      },
      "source": [
        "Use `imageio` to create an animated gif using the images saved during training."
      ]
    }
  ]
}