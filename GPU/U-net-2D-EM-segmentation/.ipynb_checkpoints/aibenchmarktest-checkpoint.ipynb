{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yxvlk_0JTa2W",
    "outputId": "6a29aa58-c0d0-4e96-e6e1-5546abd55c23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ai-benchmark\n",
      "  Downloading ai_benchmark-0.1.2-py3-none-any.whl (21.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.5 MB 11.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from ai-benchmark) (58.5.2)\n",
      "Collecting py-cpuinfo\n",
      "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 13.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting psutil\n",
      "  Downloading psutil-5.8.0-cp38-cp38-manylinux2010_x86_64.whl (296 kB)\n",
      "\u001b[K     |████████████████████████████████| 296 kB 14.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/lib/python3/dist-packages (from ai-benchmark) (2.22.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from ai-benchmark) (1.21.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from ai-benchmark) (8.4.0)\n",
      "Building wheels for collected packages: py-cpuinfo\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22256 sha256=f57c9ad737a1f782497f5784817679d6f2ba1610a5ca547d9e667d8c8987e2e0\n",
      "  Stored in directory: /root/.cache/pip/wheels/57/cb/6d/bab2257f26c5be4a96ff65c3d2a7122c96529b73773ee37f36\n",
      "Successfully built py-cpuinfo\n",
      "Installing collected packages: py-cpuinfo, psutil, ai-benchmark\n",
      "Successfully installed ai-benchmark-0.1.2 psutil-5.8.0 py-cpuinfo-8.0.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ai-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eCiXzQsGTwRe",
    "outputId": "319d6082-4612-4555-885e-82d90bb90b99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>   AI-Benchmark-v.0.1.2   \n",
      ">>   Let the AI Games begin..\n",
      "\n",
      "*  TF Version: 2.7.0\n",
      "*  Platform: Linux-5.15.5-zen1-1-zen-x86_64-with-glibc2.29\n",
      "*  CPU: N/A\n",
      "*  CPU RAM: 16 GB\n",
      "*  GPU/0: NVIDIA GeForce RTX 3080\n",
      "*  GPU RAM: 0.2 GB\n",
      "*  CUDA Version: 11.2\n",
      "*  CUDA Build: V11.2.152\n",
      "\n",
      "The benchmark is running...\n",
      "The tests might take up to 20 minutes\n",
      "Please don't interrupt the script\n",
      "\n",
      "1/19. MobileNet-V2\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[50,3,225,225] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node MobilenetV2/Conv/Conv2D\n (defined at /usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py:238)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[output/_3]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[50,3,225,225] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node MobilenetV2/Conv/Conv2D\n (defined at /usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py:238)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node MobilenetV2/Conv/Conv2D:\nIn[0] MobilenetV2/input:\t\nIn[1] MobilenetV2/Conv/weights/read:\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 540, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-2-eb3ed2f4b010>\", line 3, in <module>\n>>>     results = benchmark.run()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/__init__.py\", line 63, in run\n>>>     return run_tests(training=True, inference=True, micro=False, verbose=self.verbose,\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py\", line 557, in run_tests\n>>>     input_, output_, train_vars_ = getModelSrc(test, testInfo, sess)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py\", line 238, in getModelSrc\n>>>     tf.compat.v1.train.import_meta_graph(test.model_src, clear_devices=True)\n>>> \n\nInput Source operations connected to node MobilenetV2/Conv/Conv2D:\nIn[0] MobilenetV2/input:\t\nIn[1] MobilenetV2/Conv/weights/read:\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 540, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-2-eb3ed2f4b010>\", line 3, in <module>\n>>>     results = benchmark.run()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/__init__.py\", line 63, in run\n>>>     return run_tests(training=True, inference=True, micro=False, verbose=self.verbose,\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py\", line 557, in run_tests\n>>>     input_, output_, train_vars_ = getModelSrc(test, testInfo, sess)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py\", line 238, in getModelSrc\n>>>     tf.compat.v1.train.import_meta_graph(test.model_src, clear_devices=True)\n>>> \n\nOriginal stack trace for 'MobilenetV2/Conv/Conv2D':\n  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 540, in execute_request\n    self.do_execute(\n  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n    result = self._run_cell(\n  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-eb3ed2f4b010>\", line 3, in <module>\n    results = benchmark.run()\n  File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/__init__.py\", line 63, in run\n    return run_tests(training=True, inference=True, micro=False, verbose=self.verbose,\n  File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py\", line 557, in run_tests\n    input_, output_, train_vars_ = getModelSrc(test, testInfo, sess)\n  File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py\", line 238, in getModelSrc\n    tf.compat.v1.train.import_meta_graph(test.model_src, clear_devices=True)\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py\", line 1569, in import_meta_graph\n    return _import_meta_graph_with_return_elements(meta_graph_or_file,\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py\", line 1590, in _import_meta_graph_with_return_elements\n    meta_graph.import_scoped_meta_graph_with_return_elements(\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/meta_graph.py\", line 801, in import_scoped_meta_graph_with_return_elements\n    imported_return_elements = importer.import_graph_def(\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py\", line 552, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py\", line 407, in import_graph_def\n    return _import_graph_def_internal(\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py\", line 520, in _import_graph_def_internal\n    _ProcessNewOps(graph)\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py\", line 251, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\", line 3847, in _add_new_tf_operations\n    new_ops = [\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\", line 3848, in <listcomp>\n    self._create_op_from_tf_operation(c_op, compute_device=compute_devices)\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\", line 3730, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\", line 2101, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1362\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1364\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1455\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1456\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1457\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[50,3,225,225] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node MobilenetV2/Conv/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[output/_3]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[50,3,225,225] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node MobilenetV2/Conv/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-eb3ed2f4b010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mai_benchmark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAIBenchmark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbenchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAIBenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ai_benchmark/__init__.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, precision)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"normal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         return run_tests(training=True, inference=True, micro=False, verbose=self.verbose,\n\u001b[0m\u001b[1;32m     64\u001b[0m                          use_CPU=self.use_CPU, precision=precision, _type=\"full\", start_dir=self.cwd)\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py\u001b[0m in \u001b[0;36mrun_tests\u001b[0;34m(training, inference, micro, verbose, use_CPU, precision, _type, start_dir)\u001b[0m\n\u001b[1;32m    581\u001b[0m                             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetInputDims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m                             \u001b[0mtime_iter_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTimeMillis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m                             \u001b[0minference_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTimeMillis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_iter_started\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                             \u001b[0minference_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    971\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    972\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1194\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1195\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1374\u001b[0m                            run_metadata)\n\u001b[1;32m   1375\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1397\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1399\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[50,3,225,225] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node MobilenetV2/Conv/Conv2D\n (defined at /usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py:238)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[output/_3]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[50,3,225,225] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node MobilenetV2/Conv/Conv2D\n (defined at /usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py:238)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node MobilenetV2/Conv/Conv2D:\nIn[0] MobilenetV2/input:\t\nIn[1] MobilenetV2/Conv/weights/read:\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 540, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-2-eb3ed2f4b010>\", line 3, in <module>\n>>>     results = benchmark.run()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/__init__.py\", line 63, in run\n>>>     return run_tests(training=True, inference=True, micro=False, verbose=self.verbose,\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py\", line 557, in run_tests\n>>>     input_, output_, train_vars_ = getModelSrc(test, testInfo, sess)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py\", line 238, in getModelSrc\n>>>     tf.compat.v1.train.import_meta_graph(test.model_src, clear_devices=True)\n>>> \n\nInput Source operations connected to node MobilenetV2/Conv/Conv2D:\nIn[0] MobilenetV2/input:\t\nIn[1] MobilenetV2/Conv/weights/read:\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 540, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-2-eb3ed2f4b010>\", line 3, in <module>\n>>>     results = benchmark.run()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/__init__.py\", line 63, in run\n>>>     return run_tests(training=True, inference=True, micro=False, verbose=self.verbose,\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py\", line 557, in run_tests\n>>>     input_, output_, train_vars_ = getModelSrc(test, testInfo, sess)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py\", line 238, in getModelSrc\n>>>     tf.compat.v1.train.import_meta_graph(test.model_src, clear_devices=True)\n>>> \n\nOriginal stack trace for 'MobilenetV2/Conv/Conv2D':\n  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 540, in execute_request\n    self.do_execute(\n  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n    result = self._run_cell(\n  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-eb3ed2f4b010>\", line 3, in <module>\n    results = benchmark.run()\n  File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/__init__.py\", line 63, in run\n    return run_tests(training=True, inference=True, micro=False, verbose=self.verbose,\n  File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py\", line 557, in run_tests\n    input_, output_, train_vars_ = getModelSrc(test, testInfo, sess)\n  File \"/usr/local/lib/python3.8/dist-packages/ai_benchmark/utils.py\", line 238, in getModelSrc\n    tf.compat.v1.train.import_meta_graph(test.model_src, clear_devices=True)\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py\", line 1569, in import_meta_graph\n    return _import_meta_graph_with_return_elements(meta_graph_or_file,\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py\", line 1590, in _import_meta_graph_with_return_elements\n    meta_graph.import_scoped_meta_graph_with_return_elements(\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/meta_graph.py\", line 801, in import_scoped_meta_graph_with_return_elements\n    imported_return_elements = importer.import_graph_def(\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py\", line 552, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py\", line 407, in import_graph_def\n    return _import_graph_def_internal(\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py\", line 520, in _import_graph_def_internal\n    _ProcessNewOps(graph)\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py\", line 251, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\", line 3847, in _add_new_tf_operations\n    new_ops = [\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\", line 3848, in <listcomp>\n    self._create_op_from_tf_operation(c_op, compute_device=compute_devices)\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\", line 3730, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\", line 2101, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
     ]
    }
   ],
   "source": [
    "from ai_benchmark import AIBenchmark\n",
    "benchmark = AIBenchmark()\n",
    "results = benchmark.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "aibenchmarktest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
